13/11/17 19:01:54 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
13/11/17 19:01:54 INFO tool.CodeGenTool: Using existing jar: login.jar
13/11/17 19:01:54 WARN manager.MySQLManager: It looks like you are importing from mysql.
13/11/17 19:01:54 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
13/11/17 19:01:54 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
13/11/17 19:01:54 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
13/11/17 19:01:54 INFO mapreduce.ImportJobBase: Beginning import of login
13/11/17 19:01:54 WARN conf.Configuration: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
13/11/17 19:01:54 WARN conf.Configuration: mapred.jar is deprecated. Instead, use mapreduce.job.jar
13/11/17 19:01:55 WARN conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
13/11/17 19:01:55 INFO service.AbstractService: Service:org.apache.hadoop.yarn.client.YarnClientImpl is inited.
13/11/17 19:01:55 INFO service.AbstractService: Service:org.apache.hadoop.yarn.client.YarnClientImpl is started.
13/11/17 19:01:55 ERROR security.UserGroupInformation: PriviledgedActionException as:daemon (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:8020/user/daemon/login already exists
13/11/17 19:01:55 ERROR tool.ImportTool: Encountered IOException running import job: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:8020/user/daemon/login already exists
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:141)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:417)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:332)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1269)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1266)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1266)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1287)
	at org.apache.sqoop.mapreduce.ImportJobBase.doSubmitJob(ImportJobBase.java:186)
	at org.apache.sqoop.mapreduce.ImportJobBase.runJob(ImportJobBase.java:159)
	at org.apache.sqoop.mapreduce.ImportJobBase.runImport(ImportJobBase.java:239)
	at org.apache.sqoop.manager.SqlManager.importTable(SqlManager.java:600)
	at org.apache.sqoop.manager.MySQLManager.importTable(MySQLManager.java:118)
	at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:413)
	at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:502)
	at org.apache.sqoop.Sqoop.run(Sqoop.java:145)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:181)
	at org.apache.sqoop.Sqoop.runTool(Sqoop.java:220)
	at org.apache.sqoop.Sqoop.runTool(Sqoop.java:229)
	at org.apache.sqoop.Sqoop.main(Sqoop.java:238)

